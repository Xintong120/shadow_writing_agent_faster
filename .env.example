# Shadow Writing Agent 环境变量配置

# ==================== Memory Store配置 ====================
# 存储类型: 
#   - inmemory: 内存存储（开发/测试，重启丢失）
#   - sqlite: SQLite本地存储（桌面应用，数据持久化）
#   - postgres: PostgreSQL服务器（生产部署，多实例共享）
MEMORY_STORE_TYPE=inmemory

# SQLite配置（桌面应用使用）
# 可选：自定义数据库文件路径，留空则使用系统默认位置
# Windows: %APPDATA%\TED-Shadow-Writing\shadow_writing.db
# Mac: ~/Library/Application Support/TED-Shadow-Writing/shadow_writing.db
# Linux: ~/.config/TED-Shadow-Writing/shadow_writing.db
# SQLITE_DB_PATH=./data/shadow_writing.db

# PostgreSQL连接配置
POSTGRES_USER=shadow_writing
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=shadow_writing_db
POSTGRES_PORT=5432
POSTGRES_HOST=localhost

# PostgreSQL连接URI (自动构建或手动设置)
POSTGRES_URI=postgresql://shadow_writing:your_secure_password_here@localhost:5432/shadow_writing_db

# ==================== Langfuse配置 (可选) ====================
# 是否启用Langfuse监控
LANGFUSE_ENABLED=false

# Langfuse API配置 (用于云服务)
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_BASE_URL=https://cloud.langfuse.com

# 或者使用自托管Langfuse实例
# LANGFUSE_BASE_URL=http://localhost:3000

# ==================== API密钥配置 ====================
# Groq API Keys (多个Key用逗号分隔，支持轮换)
GROQ_API_KEYS=gsk_xxxxx1,gsk_xxxxx2,gsk_xxxxx3

# Tavily API Key (用于TED搜索)
TAVILY_API_KEY=tvly-xxxxxxxxxxxxxxxxxx

# Mistral API Keys (独立的Mistral配置，不与Groq混淆，支持轮换)
MISTRAL_API_KEY_1=your_mistral_api_key1
MISTRAL_API_KEY_2=your_mistral_api_key2
MISTRAL_API_KEY_3=your_mistral_api_key3

# ==================== LLM 模型映射配置 ====================
# 配置每个功能使用哪个 Provider + 模型 + temperature
# 格式: {"用途": {"provider": "xxx", "model": "xxx", "temperature": 0.1}, ...}
# 可用 Provider: groq, mistral, openai, deepseek, anthropic
#
# 简洁格式（兼容旧版）:
# LLM_MODEL_MAP={"debate": "groq/llama-3.3-70b-versatile", ...}
#
# 完整格式（推荐）:
# LLM_MODEL_MAP={"debate": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.7}, "shadow_writing": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}, "validation": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}, "quality_check": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}, "correction": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}, "default": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}}
#
# 说明:
# - debate: 辩论功能 (temperature=0.7)
# - shadow_writing: 影子写作功能 (temperature=0.1)
# - validation: 验证功能 (temperature=0.1)
# - quality_check: 质量检查功能 (temperature=0.1)
# - correction: 修正功能 (temperature=0.1)
# - default: 默认配置（当其他用途未配置时使用）
#
# 切换模型/调整温度只需修改对应值，无需改代码！
# 例如将 debate 改为 Claude:
# LLM_MODEL_MAP={"debate": {"provider": "anthropic", "model": "claude-3-5-sonnet", "temperature": 0.7}, ...}
LLM_MODEL_MAP={"debate": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.7}, "shadow_writing": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}, "validation": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}, "quality_check": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}, "correction": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}, "default": {"provider": "mistral", "model": "mistral-large-latest", "temperature": 0.1}}

# Mistral 模型名称
MISTRAL_MODEL_NAME=mistral-large-3

# 是否使用 Mistral 进行 Shadow Writing (true/false)
USE_MISTRAL_FOR_SHADOW_WRITING=false

# ==================== 应用配置 ====================
# FastAPI配置
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# LLM配置
MODEL_NAME=llama-3.3-70b-versatile
TEMPERATURE=0.2

# ==================== 开发配置 ====================
# 开发环境标志
DEBUG=false
LOG_LEVEL=INFO
